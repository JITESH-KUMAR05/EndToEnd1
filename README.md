# ğŸ“ Student Performance Predictor - End-to-End Machine Learning Project

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.3.3-green)](https://flask.palletsprojects.com/)
[![AWS](https://img.shields.io/badge/AWS-Elastic%20Beanstalk-orange)](https://aws.amazon.com/elasticbeanstalk/)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.7.0-red)](https://scikit-learn.org/)

## ğŸ“– Overview

This is my **first complete end-to-end machine learning project** that predicts student math scores based on various demographic and academic factors. The project demonstrates the full ML lifecycle from data ingestion to production deployment on AWS.

## ğŸ¯ Project Objectives

- Build a regression model to predict student math scores
- Create a robust ML pipeline with proper data preprocessing
- Deploy the model as a web application
- Implement CI/CD pipeline for automated deployments
- Demonstrate production-ready ML engineering practices

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Source   â”‚â”€â”€â”€â–¶â”‚  Data Pipeline   â”‚â”€â”€â”€â–¶â”‚  Model Training â”‚
â”‚   (CSV File)    â”‚    â”‚  - Ingestion     â”‚    â”‚  - Multiple     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - Validation    â”‚    â”‚    Algorithms   â”‚
                       â”‚  - Transformationâ”‚    â”‚  - Evaluation   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask Web     â”‚â—€â”€â”€â”€â”‚   Artifacts      â”‚â—€â”€â”€â”€â”‚  Best Model     â”‚
â”‚   Application   â”‚    â”‚  - model.pkl     â”‚    â”‚  Selection      â”‚
â”‚                 â”‚    â”‚  - preprocessor  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub        â”‚â”€â”€â”€â–¶â”‚  AWS CodePipelineâ”‚â”€â”€â”€â–¶â”‚ AWS Elastic     â”‚
â”‚   Repository    â”‚    â”‚  - Auto Trigger  â”‚    â”‚ Beanstalk       â”‚
â”‚                 â”‚    â”‚  - Build & Test  â”‚    â”‚ - Production    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dataset Features

The model uses the following features to predict math scores:

| Feature | Type | Description |
|---------|------|-------------|
| **Gender** | Categorical | Student's gender (male/female) |
| **Race/Ethnicity** | Categorical | Student's ethnic background (groups A-E) |
| **Parental Education** | Categorical | Highest education level of parents |
| **Lunch Type** | Categorical | Free/reduced vs standard lunch |
| **Test Preparation** | Categorical | Completed test prep course or not |
| **Reading Score** | Numerical | Score in reading test (0-100) |
| **Writing Score** | Numerical | Score in writing test (0-100) |

**Target Variable:** Math Score (0-100)

## ğŸ”§ Technical Implementation

### Data Pipeline
```
Data Ingestion â†’ Data Validation â†’ Data Transformation â†’ Model Training â†’ Model Evaluation
```

1. **Data Ingestion** (`data_ingestion.py`)
   - Loads raw dataset
   - Performs train-test split
   - Saves data artifacts

2. **Data Transformation** (`data_transformation.py`)
   - Handles categorical encoding (One-Hot Encoding)
   - Numerical feature scaling (StandardScaler)
   - Creates preprocessing pipeline
   - Saves preprocessor artifact

3. **Model Training** (`model_trainer.py`)
   - Tests multiple algorithms:
     - Linear Regression
     - Random Forest Regressor
     - Decision Tree Regressor
     - Gradient Boosting Regressor
     - AdaBoost Regressor
   - Hyperparameter tuning with GridSearchCV
   - Model evaluation and selection
   - Saves best model artifact

### ML Algorithms Tested

| Algorithm | RÂ² Score | Features |
|-----------|----------|----------|
| **Linear Regression** | ~0.88 | Simple, interpretable |
| **Random Forest** | ~0.90 | Ensemble, feature importance |
| **Gradient Boosting** | ~0.91 | Sequential learning |
| **Decision Tree** | ~0.85 | Tree-based decisions |
| **AdaBoost** | ~0.89 | Adaptive boosting |

## ğŸš€ Deployment Architecture

### AWS Infrastructure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub Repo   â”‚
â”‚   (Source Code) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Push Event
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS CodePipelineâ”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   Source    â”‚ â”‚ â† GitHub Integration
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   Build     â”‚ â”‚ â† Install Dependencies
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   Deploy    â”‚ â”‚ â† Deploy to EB
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Elastic Beanstalkâ”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   EC2       â”‚ â”‚ â† Application Server
â”‚ â”‚   Instance  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   Load      â”‚ â”‚ â† Auto Scaling
â”‚ â”‚   Balancer  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   Health    â”‚ â”‚ â† Monitoring
â”‚ â”‚   Monitoringâ”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deployment Components

1. **AWS Elastic Beanstalk**
   - Platform: Python 3.9 running on 64bit Amazon Linux 2
   - Environment: Single instance (t2.micro for cost optimization)
   - Auto-scaling and load balancing capabilities
   - Health monitoring and log management

2. **AWS CodePipeline**
   - **Source Stage**: GitHub repository integration
   - **Build Stage**: Automated dependency installation
   - **Deploy Stage**: Automatic deployment to Elastic Beanstalk
   - Triggers on every push to main branch

3. **GitHub Integration**
   - Source code version control
   - Webhook integration with CodePipeline
   - Automated CI/CD on code changes

## ğŸ› ï¸ Project Structure

```
EndToEnd1/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ exception.py          # Custom exception handling
â”‚   â”œâ”€â”€ logger.py            # Logging configuration
â”‚   â”œâ”€â”€ utlis.py             # Utility functions
â”‚   â”œâ”€â”€ ğŸ“ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py    # Data loading and splitting
â”‚   â”‚   â”œâ”€â”€ data_transformation.py # Feature engineering
â”‚   â”‚   â””â”€â”€ model_trainer.py     # Model training and evaluation
â”‚   â””â”€â”€ ğŸ“ pipeline/
â”‚       â”œâ”€â”€ predict_pipeline.py  # Prediction pipeline
â”‚       â””â”€â”€ train_pipeline.py    # Training pipeline
â”œâ”€â”€ ğŸ“ artifacts/
â”‚   â”œâ”€â”€ model.pkl            # Trained model
â”‚   â”œâ”€â”€ preprocessor.pkl     # Data preprocessor
â”‚   â””â”€â”€ *.csv               # Processed datasets
â”œâ”€â”€ ğŸ“ templates/
â”‚   â””â”€â”€ home.html           # Web application template
â”œâ”€â”€ ğŸ“ static/
â”‚   â””â”€â”€ css/style.css       # Web application styling
â”œâ”€â”€ ğŸ“ notebook/
â”‚   â”œâ”€â”€ EDA_Student_performance.ipynb  # Exploratory Data Analysis
â”‚   â””â”€â”€ Model_training.ipynb           # Model experimentation
â”œâ”€â”€ ğŸ“ .ebextensions/
â”‚   â””â”€â”€ python.config       # AWS EB configuration
â”œâ”€â”€ application.py          # Flask web application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ setup.py               # Package setup
â””â”€â”€ README.md              # Project documentation
```

## ğŸ“± Web Application Features

### User Interface
- **Modern, responsive design** with CSS Grid and Flexbox
- **Interactive form** with client-side validation
- **Real-time predictions** with loading animations
- **Result visualization** with score display
- **Mobile-friendly** responsive layout

### Backend Features
- **Flask REST API** for predictions
- **Error handling** and logging
- **Input validation** and sanitization
- **Model artifact loading** and caching
- **Production-ready** configuration

## ğŸ”§ Installation & Setup

### Local Development

1. **Clone the repository**
```bash
git clone <repository-url>
cd EndToEnd1
```

2. **Create virtual environment**
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Run the training pipeline**
```bash
python src/components/data_ingestion.py
python src/components/data_transformation.py
python src/components/model_trainer.py
```

5. **Start the web application**
```bash
python application.py
```

6. **Access the application**
   - Open browser and go to `http://localhost:5000`

### AWS Deployment Setup

1. **Create Elastic Beanstalk Application**
   - Platform: Python 3.9
   - Environment: Web server environment

2. **Setup CodePipeline**
   - Source: GitHub repository
   - Build: AWS CodeBuild (optional)
   - Deploy: Elastic Beanstalk application

3. **Configure Environment Variables**
   - Set any required environment variables in EB console

## ğŸ“ˆ Model Performance

### Evaluation Metrics
- **RÂ² Score**: 0.88+ (Linear Regression selected as best model)
- **Mean Absolute Error**: ~6.2 points
- **Root Mean Square Error**: ~8.1 points

### Feature Importance
1. **Reading Score** - Highest correlation with math performance
2. **Writing Score** - Strong predictor of overall academic ability
3. **Parental Education** - Significant socioeconomic factor
4. **Test Preparation** - Notable impact on performance
5. **Lunch Type** - Indicator of socioeconomic status

## ğŸ” Key Learnings & Challenges

### Technical Challenges Solved
1. **Package Version Compatibility**: Resolved numpy version mismatch between local and AWS environments
2. **Model Serialization**: Handled pickle compatibility across different Python environments
3. **AWS Deployment**: Configured proper WSGI settings and environment variables
4. **CI/CD Pipeline**: Set up automated deployment with proper error handling

### Best Practices Implemented
- **Modular Code Structure**: Separation of concerns with dedicated modules
- **Exception Handling**: Custom exception classes with detailed logging
- **Configuration Management**: Environment-specific configurations
- **Version Control**: Proper Git workflow with meaningful commits
- **Documentation**: Comprehensive README and code comments

## ğŸš€ Future Enhancements

### Model Improvements
- [ ] Feature engineering with polynomial features
- [ ] Advanced algorithms (XGBoost, Neural Networks)
- [ ] Hyperparameter optimization with Bayesian methods
- [ ] Cross-validation and ensemble methods

### Application Features
- [ ] User authentication and data persistence
- [ ] Batch prediction capabilities
- [ ] Model performance monitoring
- [ ] A/B testing framework
- [ ] API rate limiting and security

### Infrastructure
- [ ] Multi-environment setup (dev/staging/prod)
- [ ] Containerization with Docker
- [ ] Kubernetes deployment
- [ ] Database integration for user data
- [ ] Monitoring and alerting with CloudWatch

## ğŸ“ Contact & Support

**Author**: [Your Name]  
**Email**: [Your Email]  
**LinkedIn**: [Your LinkedIn]  
**GitHub**: [Your GitHub]

---

â­ **If you found this project helpful, please give it a star!**

This project represents my journey into practical machine learning engineering, demonstrating the complete lifecycle from data to production deployment.